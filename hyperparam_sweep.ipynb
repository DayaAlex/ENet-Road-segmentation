{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7655224,"sourceType":"datasetVersion","datasetId":4463115},{"sourceId":8329052,"sourceType":"datasetVersion","datasetId":4945897},{"sourceId":8329060,"sourceType":"datasetVersion","datasetId":4945899},{"sourceId":171912700,"sourceType":"kernelVersion"},{"sourceId":176063509,"sourceType":"kernelVersion"},{"sourceId":44003,"sourceType":"modelInstanceVersion","modelInstanceId":36953}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install -r /kaggle/input/pylit-wandb-smp-requirements/requirements.txt -q\n!pip install segmentation_models_pytorch -q\n!pip install icecream -q\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:54:48.266411Z","iopub.execute_input":"2024-05-06T19:54:48.267217Z","iopub.status.idle":"2024-05-06T19:55:19.833306Z","shell.execute_reply.started":"2024-05-06T19:54:48.267185Z","shell.execute_reply":"2024-05-06T19:55:19.832139Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom datetime import time \nimport torch\nfrom torch import nn\nimport segmentation_models_pytorch as smp\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import Dataset, DataLoader\nimport random\nimport metrics\nimport numpy as np\nimport cv2\nimport glob\nimport matplotlib.pyplot as plt\nfrom icecream import ic\n\nfrom idd_lite_helpers.idd_lite_helpers import IDD_Main_Dataset\nfrom idd_lite_helpers.idd_lite_helpers import IDDRoadSegmentationDatamodule as dmidd\n\nimport wandb\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nimport typing \nimport os\nimport math\nfrom datetime import datetime\n\n# Seed random generator for repeatibility\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:19.835197Z","iopub.execute_input":"2024-05-06T19:55:19.835536Z","iopub.status.idle":"2024-05-06T19:55:31.542910Z","shell.execute_reply.started":"2024-05-06T19:55:19.835506Z","shell.execute_reply":"2024-05-06T19:55:31.541966Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.set_float32_matmul_precision('medium' )","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:31.544072Z","iopub.execute_input":"2024-05-06T19:55:31.544360Z","iopub.status.idle":"2024-05-06T19:55:31.548704Z","shell.execute_reply.started":"2024-05-06T19:55:31.544334Z","shell.execute_reply":"2024-05-06T19:55:31.547770Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"wandb.login()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:31.552386Z","iopub.execute_input":"2024-05-06T19:55:31.553212Z","iopub.status.idle":"2024-05-06T19:55:37.117354Z","shell.execute_reply.started":"2024-05-06T19:55:31.553187Z","shell.execute_reply":"2024-05-06T19:55:37.116572Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def decode_segmap(image, threshold=0.5):#changing single channel to 3 channel\n    \n    #print(image)#RGB\n    image = image>threshold\n    #print(image.shape)\n    Background_scene = [255,255,255]\n    Road = [51, 153, 255]\n\n    label_colours = np.array([Road,Background_scene]).astype(np.uint8)\n    \n    #print(label_colours.shape)\n    r = np.zeros_like(image).astype(np.uint8)\n    g = np.zeros_like(image).astype(np.uint8)\n    b = np.zeros_like(image).astype(np.uint8)\n    \n    for l in range(2):\n        r[image == l] = label_colours[l, 0]\n        g[image == l] = label_colours[l, 1]\n        b[image == l] = label_colours[l, 2]\n\n    rgb = np.zeros((image.shape[0], image.shape[1], 3)).astype(np.uint8)\n    rgb[:, :, 0] = r\n    rgb[:, :, 1] = g\n    rgb[:, :, 2] = b\n    return rgb\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.118689Z","iopub.execute_input":"2024-05-06T19:55:37.119168Z","iopub.status.idle":"2024-05-06T19:55:37.127853Z","shell.execute_reply.started":"2024-05-06T19:55:37.119139Z","shell.execute_reply":"2024-05-06T19:55:37.126965Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BinarySegmentationForIdd(pl.LightningModule):\n    def __init__(self,\n                 model_name :str = 'unet',\n                 encoder_name : str = 'efficientnet-b2',\n                 encoder_weights :str = 'imagenet',\n                 lr_e : float = 1e-1,\n                 lr_d : float = 1e-3,\n                    ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.tp, self.fp, self.fn, self.tn = 0,0,0,0\n        self.loss_function = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits = True)\n        self.name = model_name\n        self.encoder_name = encoder_name\n        self.encoder_weights = encoder_weights\n        self.maxmiou = 1e-4\n        self.start_time = 0\n        if self.name == 'unet':\n            self.model = smp.Unet(\n                        encoder_name = self.encoder_name,\n                        encoder_weights = self.encoder_weights,\n                        in_channels = 3,\n                        classes = 1\n                        )\n        elif self.name =='deeplabv3p':\n            self.model = smp.DeepLabV3Plus(\n                        encoder_name = self.encoder_name, \n                        encoder_depth = self.encoder\n            )\n    def forward(self,x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        imgs, masks = batch\n        outputs = self(imgs)\n        train_loss = self.loss_function(outputs, masks)\n        self.log('train/train_loss', train_loss, on_step = True, on_epoch = True)\n        return train_loss\n\n    def on_validation_epoch_start(self): \n        self.val_step_outputs = []\n\n    def validation_step(self,batch, batch_idx):\n        imgs, masks = batch\n        outputs = self(imgs)#batch,channel,height, width\n        self.val_step_outputs.append(torch.sigmoid(outputs))\n        val_loss = self.loss_function(outputs, masks)\n        self.log('val/val_loss', val_loss, on_step=False, on_epoch=True)\n\n        this_tp, this_fp, this_fn, this_tn = metrics.get_stats(outputs.squeeze(), masks, mode = 'binary', threshold=0.5)\n\n        self.tp += this_tp\n        self.fp += this_fp\n        self.fn += this_fn\n        self.tn += this_tn\n\n        return val_loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam([\n            {'params': self.model.encoder.parameters(), 'lr': self.hparams.lr_e},\n            {'params': self.model.decoder.parameters(), 'lr': self.hparams.lr_d},\n            ])\n        scheduler = StepLR(optimizer, step_size=30, gamma=0.1, verbose=True)\n        return {'optimizer':optimizer,'lr_scheduler':{'scheduler': scheduler, 'monitor': 'val_loss'}}\n\n    def on_validation_epoch_end(self):\n        val_miou = metrics.iou_score(sum(self.tp), sum(self.fp), sum(self.fn), sum(self.tn), reduction = 'micro')\n        self.log('val/val_accuracy', val_miou)\n\n        if val_miou> self.maxmiou:\n            self.maxmiou = val_miou\n            checkpoint = {\n                'epochs': self.current_epoch,\n                'state_dict': self.state_dict(),\n                'miou': self.maxmiou,\n                #to do add optimizer state dict if using lr scheduler \n            }\n            torch.save(checkpoint, f'./{self.name}_{self.encoder_name}_accuracy{self.maxmiou:.4f}.pth')\n            ckpt_artifact = wandb.Artifact(\n                                f'{self.name}_artifact_ckpt', type = 'model'    \n                                )\n            ckpt_artifact.add_file(f'./{self.name}_{self.encoder_name}_accuracy{self.maxmiou:.4f}.pth')\n            self.logger.experiment.log_artifact(ckpt_artifact)\n            self.log('New best model saved with miou',self.maxmiou)\n\n        self.tp, self.fp, self.fn, self.tn = 0,0,0,0\n\n        flattened_prob = torch.flatten(torch.cat(self.val_step_outputs)).cpu().detach()\n        try:\n            self.logger.experiment.log({\n            'valid/sigmoid': wandb.Histogram(flattened_prob),\n            'epoch': self.current_epoch\n            })\n        except Exception as e:\n            print(f\"Error logging to WandB: {e}\")\n            \n    def test_step(self, batch,batch_idx):\n        imgs, masks = batch\n        outputs = self(imgs)#batch,channel,height, width\n        test_loss = self.loss_function(outputs, masks)\n        self.log('test/test_loss', test_loss, on_step=False, on_epoch=True)\n\n        this_tp, this_fp, this_fn, this_tn = metrics.get_stats(outputs.squeeze(), masks, mode = 'binary', threshold=0.5)\n\n        self.tp += this_tp\n        self.fp += this_fp\n        self.fn += this_fn\n        self.tn += this_tn\n\n        return outputs \n                \n    def on_test_epoch_start(self):\n        self.start_time = datetime.now()\n    def on_test_epoch_end(self):\n        \n        test_miou = metrics.iou_score(sum(self.tp), sum(self.fp), sum(self.fn), sum(self.tn), reduction = 'micro')\n        self.log('test/test_accuracy', test_miou)\n        final_time = datetime.now()-self.start_time \n        print('time taken for 1 epoch inference is {}'.format(final_time))\n        self.start_time = 0\n        self.tp, self.fp, self.fn, self.tn = 0,0,0,0\n        \n        #ic(self.trainer.max_epochs-1)\n        #ic(self.current_epoch)\n        if self.current_epoch == (self.trainer.max_epochs):\n            dummy_input = torch.zeros((1,3,448,448), device=self.device)\n            model_filename = f\"model_{self.name}_{self.current_epoch}.onnx\"\n            torch.onnx.export(self, dummy_input, model_filename, opset_version=11)\n            onnx_artifact = wandb.Artifact(name=f\"model_{self.name}_onnx_maxiou{self.max_iou:.4f})\", type=\"model\")\n            onnx_artifact.add_file(model_filename)\n            self.logger.experiment.log_artifact(onnx_artifact)\n            ic('exported')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.129274Z","iopub.execute_input":"2024-05-06T19:55:37.129603Z","iopub.status.idle":"2024-05-06T19:55:37.158295Z","shell.execute_reply.started":"2024-05-06T19:55:37.129579Z","shell.execute_reply":"2024-05-06T19:55:37.157475Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ImagePredictionLogger(pl.Callback):\n    def __init__(self, val_samples, num_samples=3):\n        super().__init__()\n        self.X_img_samples, self.mask_samples = val_samples\n        self.X_img_samples= self.X_img_samples[:num_samples]\n        self.mask_samples= self.mask_samples[:num_samples] \n\n    def on_validation_epoch_end(self, trainer, pl_module):#remember model is now pl_module\n\n        \n        self.X_img_samples = self.X_img_samples.to(pl_module.device)\n        output_samples = pl_module(self.X_img_samples)\n\n\n        #output_samples = output_samples*torch.Tensor([0.2588, 0.2734, 0.2997]) + torch.Tensor([0.3606, 0.3771, 0.3724])\n\n        table = wandb.Table(columns = [\"images\", \"predictions\", \"targets\"] \n            )\n        for X_img, output, mask in zip(self.X_img_samples.to(\"cpu\"), output_samples.to(\"cpu\"), self.mask_samples.to(\"cpu\")):\n            segmap_pred = decode_segmap(output.squeeze().numpy())\n            segmap_gt = decode_segmap(mask.numpy())\n\n            table.add_data(wandb.Image(X_img.numpy().transpose(1,2,0)*255), \n                    wandb.Image(segmap_pred), \n                    wandb.Image(segmap_gt)\n                    )    \n\n        trainer.logger.experiment.log(\n            {'val_images_table': table}\n        )","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.159585Z","iopub.execute_input":"2024-05-06T19:55:37.160382Z","iopub.status.idle":"2024-05-06T19:55:37.172272Z","shell.execute_reply.started":"2024-05-06T19:55:37.160350Z","shell.execute_reply":"2024-05-06T19:55:37.171603Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'random'\n    }\n\nmetric = {\n    'name': 'New best model saved with miou',\n    'goal': 'maximize'\n    }\n\nsweep_config['metric'] = metric\n\nparameters_dict = {\n    'batch_size':{\n        'values':[4,8,16,32]\n    },\n    'lr_e': {\n    'distribution': 'log_uniform_values',\n    'min': 5e-3,\n    'max': 5e-1\n    },\n    'lr_d':{\n    'distribution': 'log_uniform_values',\n    'min': 5e-5,\n    'max': 5e-3   \n    },\n    'image_ip_size':{\n        'values': [224,384,512]\n    }\n    }\n\nparameters_dict.update({\n    'epochs':{'value': 20 },\n    'model_name': {'value':'unet'},\n    'encoder_name' :  {'value':'mobilenet_v2'},\n    'encoder_weights' :{'value':'imagenet'},\n})\n\nsweep_config['parameters'] = parameters_dict","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.173447Z","iopub.execute_input":"2024-05-06T19:55:37.173697Z","iopub.status.idle":"2024-05-06T19:55:37.185467Z","shell.execute_reply.started":"2024-05-06T19:55:37.173676Z","shell.execute_reply":"2024-05-06T19:55:37.184561Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project='multiprocessed dataloader,idd_lite_unet_binary_road_segmenation',\n                )","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.186510Z","iopub.execute_input":"2024-05-06T19:55:37.186818Z","iopub.status.idle":"2024-05-06T19:55:37.638724Z","shell.execute_reply.started":"2024-05-06T19:55:37.186786Z","shell.execute_reply":"2024-05-06T19:55:37.637731Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Create sweep with ID: 2ajufm9l\nSweep URL: https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_using_wandb():\n    run = wandb.init(project = 'multiprocessed dataloader,idd_lite_unet_binary_road_segmenation',\n                config = wandb.config\n                )\n    config = run.config\n    run_name = f' 1 gpu lr {config.lr_d:.4f}, epochs {config.epochs}, batch_size: {config.batch_size}'\n    wandb.run.name = run_name\n\n    datamod = dmidd(batch_size=config.batch_size, size = config.image_ip_size)\n    datamod.setup()\n\n    model = BinarySegmentationForIdd(model_name= config.model_name,\n                                     encoder_name = config.encoder_name,\n                                     encoder_weights = config.encoder_weights,\n                                     lr_e = config.lr_e,\n                                     lr_d = config.lr_d)       \n\n    logger = WandbLogger()\n    wandb.watch(model, model.loss_function, log= 'all', log_freq = 160 )\n    val_samples = next(iter(datamod.val_dataloader()))\n\n\n    trainer = pl.Trainer(\n        accelerator=\"gpu\", devices=1,\n        logger = logger,\n        log_every_n_steps = 1,\n        max_epochs = config.epochs,\n        callbacks = [ImagePredictionLogger(val_samples)]#, gpu_stats]\n    )\n    \n    trainer.fit(model,datamod)\n    trainer.test(datamodule = datamod, ckpt_path='best')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.641371Z","iopub.execute_input":"2024-05-06T19:55:37.641676Z","iopub.status.idle":"2024-05-06T19:55:37.650175Z","shell.execute_reply.started":"2024-05-06T19:55:37.641644Z","shell.execute_reply":"2024-05-06T19:55:37.649229Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"wandb.agent(sweep_id, train_using_wandb, count=15)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T19:55:37.651396Z","iopub.execute_input":"2024-05-06T19:55:37.651737Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ov4f4yzm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_name: mobilenet_v2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_weights: imagenet\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \timage_ip_size: 224\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_d: 0.0006664921399265583\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_e: 0.17509910307480864\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: unet\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdayaalex\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_195540-ov4f4yzm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/ov4f4yzm' target=\"_blank\">dutiful-sweep-1</a></strong> to <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/ov4f4yzm' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/ov4f4yzm</a>"},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 195MB/s]\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b893ed71b6d4bef9238c48e926e2dd5"}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.7510e-01.\nAdjusting learning rate of group 1 to 6.6649e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ce52312e134358b09bd63ee6a1d095"}},"metadata":{}},{"name":"stdout","text":"time taken for 1 epoch inference is 0:00:00.379008\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:16: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if h % output_stride != 0 or w % output_stride != 0:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='131.600 MB of 131.600 MB uploaded (3.743 MB deduped)\\r'), FloatProgress(value=1.0,…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B sync reduced upload amount by 2.8%             "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>▁▄▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/train_loss_epoch</td><td>█▆▄▃▃▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train/train_loss_step</td><td>█▆▆▇▃▃▄▄▃▃▃▃▁▃▁▂▂▄▂▁▁▁▁▄▂▂▁▂▃▃▁▂▂▄▃▁▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/val_accuracy</td><td>▇▇▇▇████▅████▇▁█▇███</td></tr><tr><td>val/val_loss</td><td>▃▂▂▂▁▁▁▁▃▁▁▁▁▁█▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>0.88401</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>train/train_loss_epoch</td><td>0.07981</td></tr><tr><td>train/train_loss_step</td><td>0.09317</td></tr><tr><td>trainer/global_step</td><td>3499</td></tr><tr><td>val/val_accuracy</td><td>0.85191</td></tr><tr><td>val/val_loss</td><td>0.08689</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dutiful-sweep-1</strong> at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/ov4f4yzm' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/ov4f4yzm</a><br/> View project at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a><br/>Synced 5 W&B file(s), 21 media file(s), 213 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240506_195540-ov4f4yzm/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ov4f4yzm errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n    trainer.test(datamodule = datamod, ckpt_path='best')\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n    return call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n    return self._evaluation_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n    return self.on_run_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n    self._on_evaluation_epoch_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n    call._call_lightning_module_hook(trainer, hook_name)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n    ic('exported')\nTypeError: 'module' object is not callable\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ov4f4yzm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.test(datamodule = datamod, ckpt_path='best')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return call._call_and_handle_interrupt(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer_fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run(model, ckpt_path=ckpt_path)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run_stage()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._evaluation_loop.run()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return loop_run(self, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.on_run_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._on_evaluation_epoch_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_lightning_module_hook(trainer, hook_name)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ic('exported')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'module' object is not callable\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gvcfx4ii with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_name: mobilenet_v2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_weights: imagenet\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \timage_ip_size: 384\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_d: 0.0018916458656444849\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_e: 0.010137265480828122\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: unet\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_200716-gvcfx4ii</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/gvcfx4ii' target=\"_blank\">stoic-sweep-2</a></strong> to <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/gvcfx4ii' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/gvcfx4ii</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dac45005b9cb4ec687e207b34b53b9b5"}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0137e-02.\nAdjusting learning rate of group 1 to 1.8916e-03.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2d938438f748f7b465c7b47b8c1565"}},"metadata":{}},{"name":"stdout","text":"time taken for 1 epoch inference is 0:00:00.308434\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='286.908 MB of 286.908 MB uploaded (5.515 MB deduped)\\r'), FloatProgress(value=1.0,…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B sync reduced upload amount by 1.9%             "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/train_loss_epoch</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_loss_step</td><td>█▆▅▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▃▂▂▁▁▂▂▃▁▂▂▂▁▃▁▁▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/val_accuracy</td><td>▂▄▃▄▄▆▆▁▅▆▆▇▇▇█▇▆█▇▆</td></tr><tr><td>val/val_loss</td><td>█▅▄▃▃▂▂▄▂▂▂▁▂▁▁▁▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>0.90731</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>train/train_loss_epoch</td><td>0.0519</td></tr><tr><td>train/train_loss_step</td><td>0.06042</td></tr><tr><td>trainer/global_step</td><td>3499</td></tr><tr><td>val/val_accuracy</td><td>0.88831</td></tr><tr><td>val/val_loss</td><td>0.06104</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">stoic-sweep-2</strong> at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/gvcfx4ii' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/gvcfx4ii</a><br/> View project at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a><br/>Synced 5 W&B file(s), 21 media file(s), 219 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240506_200716-gvcfx4ii/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run gvcfx4ii errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n    trainer.test(datamodule = datamod, ckpt_path='best')\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n    return call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n    return self._evaluation_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n    return self.on_run_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n    self._on_evaluation_epoch_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n    call._call_lightning_module_hook(trainer, hook_name)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n    ic('exported')\nTypeError: 'module' object is not callable\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run gvcfx4ii errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.test(datamodule = datamod, ckpt_path='best')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return call._call_and_handle_interrupt(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer_fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run(model, ckpt_path=ckpt_path)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run_stage()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._evaluation_loop.run()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return loop_run(self, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.on_run_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._on_evaluation_epoch_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_lightning_module_hook(trainer, hook_name)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ic('exported')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'module' object is not callable\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6p2o2w37 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_name: mobilenet_v2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_weights: imagenet\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \timage_ip_size: 384\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_d: 0.0002738700435222024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_e: 0.08295981682534513\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: unet\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_202316-6p2o2w37</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/6p2o2w37' target=\"_blank\">honest-sweep-3</a></strong> to <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/6p2o2w37' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/6p2o2w37</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a77953a3ff4836bcaf904ff37af1eb"}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 8.2960e-02.\nAdjusting learning rate of group 1 to 2.7387e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b1d257a92c4609a1981c7b7985ac94"}},"metadata":{}},{"name":"stdout","text":"time taken for 1 epoch inference is 0:00:00.487405\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='186.845 MB of 186.845 MB uploaded (7.598 MB deduped)\\r'), FloatProgress(value=1.0,…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B sync reduced upload amount by 4.1%             "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>▁▆▇▇██</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/train_loss_step</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/val_accuracy</td><td>▁▆▇▃▇▇▁▄▇██▆███▇██▇█</td></tr><tr><td>val/val_loss</td><td>█▄▃▆▃▃▇▅▃▂▂▃▂▂▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>0.88413</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>train/train_loss_epoch</td><td>0.20491</td></tr><tr><td>train/train_loss_step</td><td>0.19005</td></tr><tr><td>trainer/global_step</td><td>859</td></tr><tr><td>val/val_accuracy</td><td>0.87643</td></tr><tr><td>val/val_loss</td><td>0.21024</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">honest-sweep-3</strong> at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/6p2o2w37' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/6p2o2w37</a><br/> View project at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a><br/>Synced 5 W&B file(s), 21 media file(s), 215 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240506_202316-6p2o2w37/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 6p2o2w37 errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n    trainer.test(datamodule = datamod, ckpt_path='best')\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n    return call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n    return self._evaluation_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n    return self.on_run_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n    self._on_evaluation_epoch_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n    call._call_lightning_module_hook(trainer, hook_name)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n    ic('exported')\nTypeError: 'module' object is not callable\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 6p2o2w37 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.test(datamodule = datamod, ckpt_path='best')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return call._call_and_handle_interrupt(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer_fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run(model, ckpt_path=ckpt_path)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run_stage()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._evaluation_loop.run()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return loop_run(self, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.on_run_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._on_evaluation_epoch_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_lightning_module_hook(trainer, hook_name)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ic('exported')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'module' object is not callable\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sgpkdkz7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_name: mobilenet_v2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_weights: imagenet\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \timage_ip_size: 224\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_d: 0.00027560364551408036\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_e: 0.1190308261072582\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: unet\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_203742-sgpkdkz7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/sgpkdkz7' target=\"_blank\">faithful-sweep-4</a></strong> to <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/sgpkdkz7' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/sgpkdkz7</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"089b10d68d884a6db1d89351331590d8"}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.1903e-01.\nAdjusting learning rate of group 1 to 2.7560e-04.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c2022891a6e4cabb99c7eac00f5e4a7"}},"metadata":{}},{"name":"stdout","text":"time taken for 1 epoch inference is 0:00:00.202735\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='234.547 MB of 234.547 MB uploaded (4.382 MB deduped)\\r'), FloatProgress(value=1.0,…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B sync reduced upload amount by 1.9%             "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>▁▄▅▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/train_loss_epoch</td><td>█▆▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/train_loss_step</td><td>█▆▆▆▅▄▅▅▆▄▅▅▃▅▄▃▂▄▃▃▂▃▂▃▃▂▂▂▂▂▂▂▂▂▃▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/val_accuracy</td><td>▃▁▃▅▅▆▆▄▇▆▇█▆██▇█▇▇▇</td></tr><tr><td>val/val_loss</td><td>██▇▅▅▅▅▄▃▃▃▂▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>New best model saved with miou</td><td>0.91113</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>train/train_loss_epoch</td><td>0.09561</td></tr><tr><td>train/train_loss_step</td><td>0.10187</td></tr><tr><td>trainer/global_step</td><td>1739</td></tr><tr><td>val/val_accuracy</td><td>0.90225</td></tr><tr><td>val/val_loss</td><td>0.09408</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">faithful-sweep-4</strong> at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/sgpkdkz7' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/sgpkdkz7</a><br/> View project at: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a><br/>Synced 5 W&B file(s), 21 media file(s), 219 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240506_203742-sgpkdkz7/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run sgpkdkz7 errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n    trainer.test(datamodule = datamod, ckpt_path='best')\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n    return call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n    return self._evaluation_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n    return self.on_run_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n    self._on_evaluation_epoch_end()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n    call._call_lightning_module_hook(trainer, hook_name)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n    output = fn(*args, **kwargs)\n  File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n    ic('exported')\nTypeError: 'module' object is not callable\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run sgpkdkz7 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3789722556.py\", line 32, in train_using_wandb\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.test(datamodule = datamod, ckpt_path='best')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 754, in test\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return call._call_and_handle_interrupt(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer_fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run(model, ckpt_path=ckpt_path)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run_stage()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1026, in _run_stage\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._evaluation_loop.run()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return loop_run(self, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 142, in run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.on_run_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 254, in on_run_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._on_evaluation_epoch_end()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 334, in _on_evaluation_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_lightning_module_hook(trainer, hook_name)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 157, in _call_lightning_module_hook\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/2762057267.py\", line 133, in on_test_epoch_end\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     ic('exported')\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: 'module' object is not callable\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tec195ba with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_name: mobilenet_v2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_weights: imagenet\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \timage_ip_size: 384\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_d: 5.316951303789821e-05\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_e: 0.010560056326448831\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: unet\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_204757-tec195ba</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/tec195ba' target=\"_blank\">cosmic-sweep-5</a></strong> to <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/sweeps/2ajufm9l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/tec195ba' target=\"_blank\">https://wandb.ai/dayaalex/multiprocessed%20dataloader%2Cidd_lite_unet_binary_road_segmenation/runs/tec195ba</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'model_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_name' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'encoder_weights' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_e' was locked by 'sweep' (ignored update).\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_d' was locked by 'sweep' (ignored update).\n","output_type":"stream"},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1293b3cfdec409cb92e1a2ecb9e08a3"}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Adjusting learning rate of group 0 to 1.0560e-02.\nAdjusting learning rate of group 1 to 5.3170e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93847e623354e6c856a02043cdedf15"}},"metadata":{}}]},{"cell_type":"code","source":"\n# lr_list = []\n# for lr in checkpoint['optimizer.state_dict']:\n#     lr_list.append(lr)\n# print(lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project = 'IDD_lite_hyperparametersweep_for_unet_binary_road_segmenation',\n                config = {'model_name':'unet',\n                          'encoder_name':'mobilenet_v2',\n                          'encoder_weights':'imagenet',\n                          'lr_e': 1.5720e-02,\n                          'lr_d': 1.0047e-03,\n                          'epochs':1,\n                          'batch_size':32,\n                          'image_ip_size':224\n                         }\n                )\nconfig = run.config\nrun_name = f'inference 1 gpu lr {config.lr_d:.4f}, epochs {config.epochs}, batch_size: {config.batch_size}'\nwandb.run.name = run_name\n\ndatamod = IDDRoadSegmentationDatamodule(batch_size=config.batch_size, size = config.image_ip_size)\ndatamod.setup()\n\nmodel = BinarySegmentationForIdd(model_name= config.model_name,\n                                 encoder_name = config.encoder_name,\n                                 encoder_weights = config.encoder_weights,\n                                 lr_e = 1.5720e-02,\n                                 lr_d = config.lr_d)       \n\n#wandb.watch(model, model.loss_function, log= 'all', log_freq = 1800 )#log every 360th batch, the grad, weights\n\n\n\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/unet-mobilenetv2/pytorch/91miou/1/unet_mobilenet_v2_accuracy0.9138.pth')\nmodel.load_state_dict(checkpoint['state_dict'])\nlogger = WandbLogger()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.test(datamodule = datamod, ckpt_path = '/kaggle/input/unet-mobilenetv2/pytorch/91miou/1/unet_mobilenet_v2_accuracy0.9138.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_images(model, image, h, w):\n  \n    image = cv2.resize(image,(224,224))\n    \n    #print(image.shape)\n    image_tensor = torch.tensor(image, dtype=torch.float32)\n    image_tensor = image_tensor / 255.0  # Normalize to [0, 1]\n    image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0) \n    model.eval()\n    with torch.inference_mode():\n        pred_mask = model(image_tensor)\n        \n    mask = pred_mask.squeeze()>0.5\n    zero_image = np.zeros_like(mask)\n    mask = np.stack((mask, mask, mask), axis=-1)*255\n    mask = np.asarray(mask, np.uint8)\n#     print(\"Image shape:\", image.shape)\n#     print(\"Mask shape:\", mask.shape)\n    \n    \n    final_image = cv2.addWeighted(image, 1.0,mask,0.5,0.0)\n    final_image = cv2.resize(final_image, (w, h))\n    return final_image\n\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/inf-vid-2/A_ one_ minute_tour_of_RIT_2k17_(www.KeepVid.to)_BIG.mp4'\nvid_object = cv2.VideoCapture(path)\nframe_width = int(vid_object.get(3))\nframe_height = int(vid_object.get(4))\n\nfourcc = cv2.VideoWriter_fourcc('m','p','4','v')\nfps =vid_object.get(cv2.CAP_PROP_FPS)\nprint(fps)\noutput = cv2.VideoWriter(\n          '/kaggle/working/A_one_ minute_tour_of_RIT_2k17_(www.KeepVid.to)_BIG.mp4',\n          fourcc,\n          fps,\n          (frame_width,frame_height)\n        )\n\nwhile(vid_object.isOpened()):\n    \n    ret, frame = vid_object.read()\n    if ret == True:\n#         print('working')\n        tqdm(output.write(process_images(model,frame,frame_height, frame_width)))\n    else:\n        break\nvid_object.release()\noutput.release()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\n","metadata":{},"execution_count":null,"outputs":[]}]}
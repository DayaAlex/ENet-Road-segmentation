































100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [01:03<00:00,  5.77it/s]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:04<00:00, 87.57it/s]
/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
   | Name     | Type          | Params
--------------------------------------------
0  | loss     | loss_function | 0
1  | init     | InitialBlock  | 412
2  | b10      | DownRDDNeck   | 4.5 K
3  | b11      | RDDNeck       | 4.5 K
4  | b12      | RDDNeck       | 4.5 K
5  | b13      | RDDNeck       | 4.5 K
6  | b14      | RDDNeck       | 4.5 K
7  | b20      | DownRDDNeck   | 21.9 K
8  | b21      | RDDNeck       | 17.8 K
9  | b22      | RDDNeck       | 17.8 K
10 | b23      | ASNeck        | 18.8 K
11 | b24      | RDDNeck       | 17.8 K
12 | b25      | RDDNeck       | 17.8 K
13 | b26      | RDDNeck       | 17.8 K
14 | b27      | ASNeck        | 18.8 K
15 | b28      | RDDNeck       | 17.8 K
16 | b31      | RDDNeck       | 17.8 K
17 | b32      | RDDNeck       | 17.8 K
18 | b33      | ASNeck        | 18.8 K
19 | b34      | RDDNeck       | 17.8 K
20 | b35      | RDDNeck       | 17.8 K
21 | b36      | RDDNeck       | 17.8 K
22 | b37      | ASNeck        | 18.8 K
23 | b38      | RDDNeck       | 17.8 K
24 | enc_conv | Conv2d        | 1.5 K
--------------------------------------------
334 K     Trainable params
0         Non-trainable params
334 K     Total params
1.339     Total estimated model params size (MB)
/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.

Sanity Checking DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  0.65it/s]
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/ENet-Road-segmentation/train.py", line 43, in <module>
    trainer.fit(model, datamod)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1031, in _run_stage
    self._run_sanity_check()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1060, in _run_sanity_check
    val_loop.run()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 157, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/teamspace/studios/this_studio/ENet-Road-segmentation/model.py", line 705, in on_validation_epoch_end
    flattened_logits = torch.flatten(torch.cat(self.val_step_outputs))
TypeError: expected Tensor as element 0 in argument 0, but got Softmax
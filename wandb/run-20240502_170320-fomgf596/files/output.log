

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:04<00:00, 88.79it/s]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:04<00:00, 88.11it/s]
/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
   | Name     | Type          | Params
--------------------------------------------
0  | loss     | loss_function | 0
1  | init     | InitialBlock  | 412
2  | b10      | DownRDDNeck   | 4.5 K
3  | b11      | RDDNeck       | 4.5 K
4  | b12      | RDDNeck       | 4.5 K
5  | b13      | RDDNeck       | 4.5 K
6  | b14      | RDDNeck       | 4.5 K
7  | b20      | DownRDDNeck   | 21.9 K
8  | b21      | RDDNeck       | 17.8 K
9  | b22      | RDDNeck       | 17.8 K
10 | b23      | ASNeck        | 18.8 K
11 | b24      | RDDNeck       | 17.8 K
12 | b25      | RDDNeck       | 17.8 K
13 | b26      | RDDNeck       | 17.8 K
14 | b27      | ASNeck        | 18.8 K
15 | b28      | RDDNeck       | 17.8 K
16 | b31      | RDDNeck       | 17.8 K
17 | b32      | RDDNeck       | 17.8 K
18 | b33      | ASNeck        | 18.8 K
19 | b34      | RDDNeck       | 17.8 K
20 | b35      | RDDNeck       | 17.8 K
21 | b36      | RDDNeck       | 17.8 K
22 | b37      | ASNeck        | 18.8 K
23 | b38      | RDDNeck       | 17.8 K
24 | enc_conv | Conv2d        | 1.5 K
--------------------------------------------
334 K     Trainable params
0         Non-trainable params
334 K     Total params
1.339     Total estimated model params size (MB)
/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.

Epoch 0:   0%|                                                                                                          | 0/37 [00:00<?, ?it/s]




































Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████| 37/37 [01:23<00:00,  0.44it/s, v_num=f596]





Validation DataLoader 0:  91%|█████████████████████████████████████████████████████████████████████████▋       | 10/11 [00:09<00:00,  1.10it/s]
`Trainer.fit` stopped: `max_epochs=1` reached.

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 367/367 [00:04<00:00, 84.18it/s]
Restoring states from the checkpoint path at Best
Traceback (most recent call last):
  File "/teamspace/studios/this_studio/ENet-Road-segmentation/train.py", line 44, in <module>
    trainer.test(datamodule = datamod, ckpt_path = 'Best')
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 754, in test
    return call._call_and_handle_interrupt(
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 956, in _run
    self._checkpoint_connector._restore_modules_and_callbacks(ckpt_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 397, in _restore_modules_and_callbacks
    self.resume_start(checkpoint_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 79, in resume_start
    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 368, in load_checkpoint
    return self.checkpoint_io.load_checkpoint(checkpoint_path)
  File "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning_fabric/plugins/io/torch_io.py", line 81, in load_checkpoint
    raise FileNotFoundError(f"Checkpoint file not found: {path}")
FileNotFoundError: Checkpoint file not found: Best